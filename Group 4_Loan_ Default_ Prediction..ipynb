{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Default Prediction\n",
    "\n",
    "# Group 4\n",
    "\n",
    "# Group Members -\n",
    "\n",
    "# Anuksha jain - 015002\n",
    "# Ayushi Gupta - 015005\n",
    "# Aniket Nandy - 015015\n",
    "# Biswadip Das - 015025\n",
    "# Siddharth Gupta - 015045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Splitting data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(r\"C:\\Users\\nandy\\Downloads\\train_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f770</th>\n",
       "      <th>f771</th>\n",
       "      <th>f772</th>\n",
       "      <th>f773</th>\n",
       "      <th>f774</th>\n",
       "      <th>f775</th>\n",
       "      <th>f776</th>\n",
       "      <th>f777</th>\n",
       "      <th>f778</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.686842</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>13699</td>\n",
       "      <td>7201.0</td>\n",
       "      <td>4949.0</td>\n",
       "      <td>126.75</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.7873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>10</td>\n",
       "      <td>0.782776</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>84645</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>123.52</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>-0.6787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500080</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>83607</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>127.76</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2.89</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>10</td>\n",
       "      <td>0.439874</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>82642</td>\n",
       "      <td>7542.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>132.94</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.2498</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>9</td>\n",
       "      <td>0.502749</td>\n",
       "      <td>2900</td>\n",
       "      <td>4</td>\n",
       "      <td>79124</td>\n",
       "      <td>89.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>122.72</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>6.11</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>-0.5399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   f1  f2        f3    f4  f5     f6      f7      f8      f9  ...  f770  \\\n",
       "0   1  126  10  0.686842  1100   3  13699  7201.0  4949.0  126.75  ...     5   \n",
       "1   2  121  10  0.782776  1100   3  84645   240.0  1625.0  123.52  ...     6   \n",
       "2   3  126  10  0.500080  1100   3  83607  1800.0  1527.0  127.76  ...    13   \n",
       "3   4  134  10  0.439874  1100   3  82642  7542.0  1730.0  132.94  ...     4   \n",
       "4   5  109   9  0.502749  2900   4  79124    89.0   491.0  122.72  ...    26   \n",
       "\n",
       "   f771  f772  f773    f774    f775  f776  f777  f778  loss  \n",
       "0  2.14 -1.54  1.18  0.1833  0.7873     1     0     5     0  \n",
       "1  0.54 -0.24  0.13  0.1926 -0.6787     1     0     5     0  \n",
       "2  2.89 -1.73  1.04  0.2521  0.7258     1     0     5     0  \n",
       "3  1.29 -0.89  0.66  0.2498  0.7119     1     0     5     0  \n",
       "4  6.11 -3.82  2.51  0.2282 -0.5399     0     0     5     0  \n",
       "\n",
       "[5 rows x 771 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105471, 771)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105471 entries, 0 to 105470\n",
      "Columns: 771 entries, id to loss\n",
      "dtypes: float64(653), int64(99), object(19)\n",
      "memory usage: 620.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "f1         0\n",
       "f2         0\n",
       "f3         0\n",
       "f4         0\n",
       "        ... \n",
       "f775    1525\n",
       "f776       0\n",
       "f777       0\n",
       "f778       0\n",
       "loss       0\n",
       "Length: 771, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105471, 771)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Missing Values\n",
    "\n",
    "# Function to calculate missing values by column\n",
    "def total_missing_values(train):\n",
    "        # Total missing values\n",
    "        count_nulls = train.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        null_percentage = 100 * train.isnull().sum() / len(train)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        null_data = pd.concat([count_nulls, null_percentage], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        null_data_ren_columns = null_data.rename(columns = {0 : 'null values', 1 : 'null_percent'})\n",
    "        \n",
    "        null_data_ren_columns = null_data_ren_columns[\n",
    "        null_data_ren_columns.iloc[:,1] != 0].sort_values('null_percent', ascending=False).round(1)\n",
    "        \n",
    "        # Print some information\n",
    "        print ('Train is having ' + str(train.shape[1]) + \" columns\"      \n",
    "            \" and \" + str(null_data_ren_columns.shape[0]) +\n",
    "              \" columns with null values.\")\n",
    "       \n",
    "        return null_data_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train is having 771 columns and 525 columns with null values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null values</th>\n",
       "      <th>null_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f662</th>\n",
       "      <td>18833</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f663</th>\n",
       "      <td>18833</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f159</th>\n",
       "      <td>18736</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f160</th>\n",
       "      <td>18736</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f170</th>\n",
       "      <td>18417</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f169</th>\n",
       "      <td>18417</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f618</th>\n",
       "      <td>18407</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f619</th>\n",
       "      <td>18407</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f331</th>\n",
       "      <td>18067</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f330</th>\n",
       "      <td>18067</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      null values  null_percent\n",
       "f662        18833          17.9\n",
       "f663        18833          17.9\n",
       "f159        18736          17.8\n",
       "f160        18736          17.8\n",
       "f170        18417          17.5\n",
       "f169        18417          17.5\n",
       "f618        18407          17.5\n",
       "f619        18407          17.5\n",
       "f331        18067          17.1\n",
       "f330        18067          17.1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_missing_values(train).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(train.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train is having 771 columns and 12 columns with null values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null values</th>\n",
       "      <th>null_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f206</th>\n",
       "      <td>1291</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f207</th>\n",
       "      <td>1291</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f390</th>\n",
       "      <td>698</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f391</th>\n",
       "      <td>698</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f626</th>\n",
       "      <td>698</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f627</th>\n",
       "      <td>698</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f695</th>\n",
       "      <td>698</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f698</th>\n",
       "      <td>698</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f138</th>\n",
       "      <td>182</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f137</th>\n",
       "      <td>177</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      null values  null_percent\n",
       "f206         1291           1.2\n",
       "f207         1291           1.2\n",
       "f390          698           0.7\n",
       "f391          698           0.7\n",
       "f626          698           0.7\n",
       "f627          698           0.7\n",
       "f695          698           0.7\n",
       "f698          698           0.7\n",
       "f138          182           0.2\n",
       "f137          177           0.2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_missing_values(train).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train is having 771 columns and 0 columns with null values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null values</th>\n",
       "      <th>null_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [null values, null_percent]\n",
       "Index: []"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dropna(inplace=True)\n",
    "total_missing_values(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103302, 771)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss    1.000000\n",
       "f471    0.039538\n",
       "f536    0.026087\n",
       "f674    0.018999\n",
       "f67     0.015012\n",
       "f670    0.014811\n",
       "f597    0.014165\n",
       "f599    0.014165\n",
       "f68     0.013375\n",
       "f13     0.011933\n",
       "Name: loss, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Correlations between Features and Target\n",
    "corr=train.corr()\n",
    "corr['loss'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f738   -0.008635\n",
       "f734   -0.009284\n",
       "f322   -0.009299\n",
       "f69    -0.010269\n",
       "f323   -0.010676\n",
       "f314   -0.010689\n",
       "f70    -0.010740\n",
       "f315   -0.011106\n",
       "f776   -0.015111\n",
       "f612   -0.016943\n",
       "Name: loss, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr['loss'].sort_values(ascending = False,na_position ='first').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103302, 771)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid:  93660\n",
      "Fraud:  1134\n",
      "fraction of fraud:  0.011962782454585734\n"
     ]
    }
   ],
   "source": [
    "Fraud = train.loc[train['loss']==1]\n",
    "\n",
    "Valid = train.loc[train['loss']==0]\n",
    "\n",
    "fraction = len(Fraud)/(len(Fraud)+len(Valid))\n",
    "\n",
    "print(\"Valid: \",len(Valid))\n",
    "\n",
    "print(\"Fraud: \",len(Fraud))\n",
    "\n",
    "print(\"fraction of fraud: \",fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the collinear features above a specified correlation coefficient\n",
    "train = remove_collinear_features(train, 0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103302, 186)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82641, 185)\n",
      "(20661, 185)\n",
      "(82641, 1)\n",
      "(20661, 1)\n"
     ]
    }
   ],
   "source": [
    "# # # Split Into Training and Testing Sets\n",
    "\n",
    "# Separate out the features and targets\n",
    "features = train.drop(columns='loss')\n",
    "targets = pd.DataFrame(train['loss'])\n",
    "\n",
    "# Split into 80% training and 20% testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y to one-dimensional array (vector)\n",
    "y_train = np.array(y_train).reshape((-1, ))\n",
    "y_test = np.array(y_test).reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06877109, -0.16688215,  1.03564494, ...,  0.        ,\n",
       "         0.65159233, -0.66443318],\n",
       "       [-0.48425848,  2.15138579, -0.14682708, ...,  0.        ,\n",
       "         0.74503266, -0.66443318],\n",
       "       [-0.43576466,  1.60591098, -0.73806309, ...,  0.        ,\n",
       "         1.24726226,  1.50504223],\n",
       "       ...,\n",
       "       [ 0.84197055, -0.57598826,  1.03564494, ...,  0.        ,\n",
       "        -0.75457294,  1.50504223],\n",
       "       [-1.69955094, -0.64417261,  0.44440893, ...,  0.        ,\n",
       "        -0.4115703 , -0.66443318],\n",
       "       [-1.20154789,  1.06043617, -0.14682708, ...,  0.        ,\n",
       "         0.87515049, -0.66443318]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47027681, -1.18964742,  1.03564494, ...,  0.        ,\n",
       "         4.19883151,  1.50504223],\n",
       "       [ 0.34727464,  1.67409533, -0.73806309, ...,  0.        ,\n",
       "         0.76570014, -0.66443318],\n",
       "       [ 1.02805453, -0.3714352 , -2.51177113, ...,  0.        ,\n",
       "         1.03078733,  1.50504223],\n",
       "       ...,\n",
       "       [ 0.29720911,  0.92406747, -0.73806309, ...,  0.        ,\n",
       "        -0.70741614, -0.66443318],\n",
       "       [ 0.85975052, -0.91691001,  1.03564494, ...,  0.        ,\n",
       "        -0.90497014,  1.50504223],\n",
       "       [ 0.00752321, -1.18964742, -1.3292991 , ...,  0.        ,\n",
       "         0.69224809, -0.66443318]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    " # RandomForest with Bayes optimization\n",
    "# xgboost with Bayes optimization\n",
    "# Lightgbm with Bayes optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian optimization\n",
    "def bayesian_optimization(dataset, function, parameters):\n",
    "   X_train, y_train, X_test, y_test = dataset\n",
    "   n_iterations = 5\n",
    "   gp_params = {\"alpha\": 1e-4}\n",
    "\n",
    "   BO = BayesianOptimization(function, parameters)\n",
    "   BO.maximize(n_iter=n_iterations, **gp_params)\n",
    "\n",
    "   return BO.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_optimization(cv_splits):\n",
    "    def function(n_estimators, max_depth, min_samples_split):\n",
    "        return cross_val_score(\n",
    "               RandomForestClassifier(\n",
    "                   n_estimators=int(max(n_estimators,0)),                                                               \n",
    "                   max_depth=int(max(max_depth,1)),\n",
    "                   min_samples_split=int(max(min_samples_split,2)), \n",
    "                   n_jobs=-1, \n",
    "                   random_state=42,   \n",
    "                   class_weight=\"balanced\"),  \n",
    "               X=X_train, \n",
    "               y=y_train, \n",
    "               cv=cv_splits,\n",
    "               scoring=\"roc_auc\",\n",
    "               n_jobs=-1).mean()\n",
    "\n",
    "    parameters = {\"n_estimators\": (10, 1000),\n",
    "                  \"max_depth\": (1, 150),\n",
    "                  \"min_samples_split\": (2, 10)}\n",
    "    \n",
    "    return function, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_optimization(cv_splits, eval_set):\n",
    "    def function(eta, gamma, max_depth):\n",
    "            return cross_val_score(\n",
    "                   xgb.XGBClassifier(\n",
    "                       objective=\"binary:logistic\",\n",
    "                       learning_rate=max(eta, 0),\n",
    "                       gamma=max(gamma, 0),\n",
    "                       max_depth=int(max_depth),                                               \n",
    "                       seed=42,\n",
    "                       nthread=-1,\n",
    "                       scale_pos_weight = len(y_train[y_train == 0])/\n",
    "                                          len(y_train[y_train == 1])),  \n",
    "                   X=X_train, \n",
    "                   y=y_train, \n",
    "                   cv=cv_splits,\n",
    "                   scoring=\"roc_auc\",\n",
    "                   fit_params={\n",
    "                        \"early_stopping_rounds\": 10, \n",
    "                        \"eval_metric\": \"auc\", \n",
    "                        \"eval_set\": eval_set},\n",
    "                   n_jobs=-1).mean()\n",
    "\n",
    "    parameters = {\"eta\": (0.001, 0.4),\n",
    "                  \"gamma\": (0, 20),\n",
    "                  \"max_depth\": (1, 2000)}\n",
    "    \n",
    "    return function, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "def train(X_train, y_train, X_test, y_test, function, parameters):\n",
    "    dataset = (X_train, y_train, X_test, y_test)\n",
    "    cv_splits = 4\n",
    "    \n",
    "    best_solution = bayesian_optimization(dataset, function, parameters)      \n",
    "    params = best_solution[\"params\"]\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "             n_estimators=int(max(params[\"n_estimators\"], 0)),\n",
    "             max_depth=int(max(params[\"max_depth\"], 1)),\n",
    "             min_samples_split=int(max(params[\"min_samples_split\"], 2)), \n",
    "             n_jobs=-1, \n",
    "             random_state=42,   \n",
    "             class_weight=\"balanced\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1267\n",
      "[LightGBM] [Info] Number of data points in the train set: 37758, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 3935.724588\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 857.111\n",
      "[200]\tvalid_0's rmse: 576.605\n",
      "[300]\tvalid_0's rmse: 546.569\n",
      "[400]\tvalid_0's rmse: 540.681\n",
      "[500]\tvalid_0's rmse: 538.675\n",
      "[600]\tvalid_0's rmse: 537.972\n",
      "Early stopping, best iteration is:\n",
      "[613]\tvalid_0's rmse: 537.86\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "train = sns.load_dataset('diamonds')\n",
    "\n",
    "train[\"color\"] = train[\"color\"].astype('category')\n",
    "train[\"color_cat\"] = train[\"color\"].cat.codes\n",
    "train = train.drop([\"color\"],axis = 1)\n",
    "\n",
    "train[\"cut\"] = train[\"cut\"].astype('category')\n",
    "train[\"cut_cat\"] = train[\"cut\"].cat.codes\n",
    "train = train.drop([\"cut\"],axis = 1)\n",
    "\n",
    "train[\"clarity\"] = train[\"clarity\"].astype('category')\n",
    "train[\"clarity_cat\"] = train[\"clarity\"].cat.codes\n",
    "train = train.drop([\"clarity\"],axis = 1)\n",
    "\n",
    "y = train['price']\n",
    "X = train.drop(['price'], axis=1)\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,random_state=seed)\n",
    "\n",
    "train_lgb = lgb.Dataset(X_train, y_train)\n",
    "eval_lgb = lgb.Dataset(X_test, y_test, reference = train_lgb)\n",
    "\n",
    "params = { 'objective': 'regression',\n",
    "  'metric': 'RMSE',\n",
    "  'learning_rate': 0.02}\n",
    "lgb_reg = lgb.train(params, train_lgb, num_boost_round = 10000, early_stopping_rounds=50, verbose_eval = 100, valid_sets=eval_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | maxDepth  | num_le... | subsample |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-541.4   \u001b[0m | \u001b[0m 0.8834  \u001b[0m | \u001b[0m 4.161   \u001b[0m | \u001b[0m 24.0    \u001b[0m | \u001b[0m 0.8605  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-628.4   \u001b[0m | \u001b[0m 0.8294  \u001b[0m | \u001b[0m 2.277   \u001b[0m | \u001b[0m 27.91   \u001b[0m | \u001b[0m 0.8691  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-565.2   \u001b[0m | \u001b[0m 0.8794  \u001b[0m | \u001b[0m 3.616   \u001b[0m | \u001b[0m 32.8    \u001b[0m | \u001b[0m 0.937   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-541.4   \u001b[0m | \u001b[0m 0.8409  \u001b[0m | \u001b[0m 4.634   \u001b[0m | \u001b[0m 24.58   \u001b[0m | \u001b[0m 0.9341  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-565.2   \u001b[0m | \u001b[0m 0.8835  \u001b[0m | \u001b[0m 3.676   \u001b[0m | \u001b[0m 26.95   \u001b[0m | \u001b[0m 0.8396  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-628.4   \u001b[0m | \u001b[0m 0.8018  \u001b[0m | \u001b[0m 2.036   \u001b[0m | \u001b[0m 24.0    \u001b[0m | \u001b[0m 0.8074  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-544.8   \u001b[0m | \u001b[0m 0.9847  \u001b[0m | \u001b[0m 4.934   \u001b[0m | \u001b[0m 26.07   \u001b[0m | \u001b[0m 0.8586  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-541.4   \u001b[0m | \u001b[0m 0.9301  \u001b[0m | \u001b[0m 4.725   \u001b[0m | \u001b[0m 35.8    \u001b[0m | \u001b[0m 0.9746  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-624.3   \u001b[0m | \u001b[0m 0.8398  \u001b[0m | \u001b[0m 2.771   \u001b[0m | \u001b[0m 36.43   \u001b[0m | \u001b[0m 0.9047  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-544.8   \u001b[0m | \u001b[0m 0.9825  \u001b[0m | \u001b[0m 4.996   \u001b[0m | \u001b[0m 34.43   \u001b[0m | \u001b[0m 0.8723  \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "def modelFitter(colsampleByTree, subsample,maxDepth, num_leaves):   \n",
    "    model = lgb.LGBMRegressor(learning_rate=0.02, n_estimators=10000, max_depth=maxDepth.astype(\"int32\"), subsample=subsample, colsample_bytree=colsampleByTree,num_leaves=num_leaves.astype(\"int32\"))\n",
    "\n",
    "    evalSet  = [(X_test, y_test)]\n",
    "    model.fit(X_train, y_train, eval_metric=\"rmse\", eval_set=evalSet, early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "    bestScore = model.best_score_[list(model.best_score_.keys())[0]]['rmse']\n",
    "\n",
    "    return -bestScore\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'colsampleByTree': (0.8,1.0), 'subsample': (0.8,1.0), 'maxDepth': (2,5), 'num_leaves': (24, 45)}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=modelFitter,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1)\n",
    "\n",
    "optimizer.maximize(init_points=5,n_iter=5)  #n_iter=bayesian, init_points=random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
